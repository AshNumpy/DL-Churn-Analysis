{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "X_train = pd.read_csv('../Datasets/X_train.csv')\n",
    "X_test = pd.read_csv('../Datasets/X_test.csv')\n",
    "y_train = pd.read_csv('../Datasets/y_train.csv')\n",
    "y_test = pd.read_csv('../Datasets/y_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Keras Models**  \n",
    "There are three ways to create Keras models:  \n",
    "- The *\"Sequential model\"*, which is very straightforward (a simple list of layers), but is limited to single-input, single-output stacks of layers (as the name gives away).  \n",
    "- The *\"Functional API\"*, which is an easy-to-use, fully-featured API that supports arbitrary model architectures. For most people and most use cases, this is what you should be using. This is the Keras \"industry strength\" model.  \n",
    "- *\"Model subclassing\"*, where you implement everything from scratch on your own. Use this if you have complex, out-of-the-box research use cases.  \n",
    "  \n",
    "We will be use **\"Sequential model\"**  \n",
    "  \n",
    "#### **Keras Layers**  \n",
    "Layers are the basic building blocks of neural networks in Keras. A layer consists of a tensor-in tensor-out computation function (the layer's call method) and some state, held in TensorFlow variables (the layer's weights).  \n",
    "  \n",
    "For more information you can visit [here][def]\n",
    "\n",
    "[def]: https://keras.io/api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "classifier = Sequential() # this is gonna be our neural network\n",
    "\n",
    "classifier.add(Dense(6, kernel_initializer='uniform', activation='relu' , input_dim=11)) # 6 functions on hidden layer 1\n",
    "classifier.add(Dense(6, kernel_initializer='uniform', activation='relu')) # 6 functions on hidden layer 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Set Hidden Layers**  \n",
    "! Warning: Theese are not rules. There are many tuning types or ways in deep learning but I will tell you some ideas.  \n",
    "  \n",
    "Tuning the hidden layers can be most popular subject of neural networks. \"What should we set layer number equal to?\" question is the one of them.  \n",
    "  \n",
    "<img src=\"https://miro.medium.com/max/1400/0*fny6vMZG5rJWCmAM\" width='600' height='400'>  \n",
    "  \n",
    "As you can see from the image we have some hidden layers to between input and output layer.  \n",
    "Think about our topic. We have 11 independent input layer such as *'Gender', 'Age', 'Tenure' etc.*  \n",
    "Also we have output layer that can answer the \"will customer churn?\" question with 0-1 and this layer just 1 dependent layer.  \n",
    "When you look at the upper image and thinking the 13 input and just 1 output layer we have, but don't now how much hidden layer inside.  \n",
    "  \n",
    "At this point we can use triangle shape:  \n",
    "  \n",
    "<img src=\"https://miro.medium.com/max/1002/1*gAMNusemlDZOvwTN1WKKhQ.png\" width='600' height='400'>  \n",
    "  \n",
    "So I'll use 6 functions on 2 hidden layers. Of course can be used 7 functions on 1st hidden layer and 3 functions on 2nd hiden layer, theese are not rules.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating output layer\n",
    "classifier.add(Dense(1, kernel_initializer='uniform', activation='sigmoid')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Optimizers**  \n",
    "There are many optimization methods for deep learning. As I told you there are not rules on this subject, esencially deep learning like an art.  \n",
    "  \n",
    "Usage with `.compile()` and `.fit()`.  \n",
    "  \n",
    "An optimizer is one of the two arguments required for compiling a Keras model  \n",
    "  \n",
    "**Available Optimizers:**  \n",
    "- [SGD][def1]\n",
    "- [RMSprop][def2]\n",
    "- [Adam][def3]\n",
    "- [Adadelta][def4]\n",
    "- [Adagrad][def5]\n",
    "- [Adamax][def6]\n",
    "- [Nadam][def7]\n",
    "- [Ftrl][def8]  \n",
    "  \n",
    "I'll use [*'adam'*][def3] optimizer\n",
    "  \n",
    "Adam:  \n",
    "Optimizer that implements the Adam algorithm.\n",
    "  \n",
    "Adam optimization is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments.\n",
    "  \n",
    "According to Kingma et al., 2014, the method is \"computationally efficient, has little memory requirement, invariant to diagonal rescaling of gradients, and is well suited for problems that are large in terms of data/parameters\".\n",
    "  \n",
    "[def1]: https://keras.io/api/optimizers/sgd\n",
    "[def2]: https://keras.io/api/optimizers/rmsprop\n",
    "[def3]: https://keras.io/api/optimizers/adam\n",
    "[def4]: https://keras.io/api/optimizers/adadelta\n",
    "[def5]: https://keras.io/api/optimizers/adagrad\n",
    "[def6]: https://keras.io/api/optimizers/adamax\n",
    "[def7]: https://keras.io/api/optimizers/Nadam\n",
    "[def8]: https://keras.io/api/optimizers/ftrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 0s 994us/step\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, epochs=50, verbose=0) # neural network will learn from train data 50 times\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **`.fit()` and `.predict()`:**  \n",
    "  \n",
    "We can use `.fit()` and `.predict()` functions like machine learning models.  \n",
    "at this point when we can fitting the neural network we can describe some hyperparameters:  \n",
    "- *epochs:* how many times the neural network will learn from train data  \n",
    "- *verbose:* do you want to see process of the fitting use `verbose=1` if u dont set it equal to 0.  \n",
    "- etc...   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20791489],\n",
       "       [0.20791489],\n",
       "       [0.20791489],\n",
       "       ...,\n",
       "       [0.20791489],\n",
       "       [0.20791489],\n",
       "       [0.20791489]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the results format is float, but we expected it will churn (1) or not (0).  \n",
    "Actually output tells us to that customer will churn xx.xx%  \n",
    "I mean if it result 0.2054 that mean that customer will churn 20.54%  \n",
    "  \n",
    "Lets encode the output binary and calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'79.79%'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.multiply((y_pred > 0.5), 1)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = ((cm[0][0] + cm[1][1]) / cm.sum())*100\n",
    "f'{round(accuracy, 2)}%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Result**  \n",
    "Our neural networks accuracy rate is 79,79% "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "578ce5a4903d7b45920c2d79663ce2541e7c0226009dc3f8451a28c8417bba54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
